{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word and countryfinding.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/vinayk19/Assignment/blob/master/word_and_countryfinding.ipynb",
      "authorship_tag": "ABX9TyNI2RyDbJH+OKpiviVQLhPI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayk19/Assignment/blob/master/word_and_countryfinding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WigN-7SHh93O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f66b1b91-4690-4ea0-c0f8-fded8e5b413c"
      },
      "source": [
        "cd /content/drive/My Drive/AI/basic/data/names_train"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI/basic/data/names_train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4jmwmZDk8U6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# from name_dataset import NameDataset\n",
        "# from torch.nn.utils.rnn import pack_padded_sequence, pad_paked_sequence"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP7rj3DGBMSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# xy1 = pd.read_csv(\"names_test.csv\") #q is it require to convert it(text) into torch\n",
        "# xy1.shape\n",
        "# name = (xy1.iloc[0,:][0])\n",
        "# name"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPr7qIASeOAW",
        "colab_type": "text"
      },
      "source": [
        "Tast1 : create database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI8_0khQiL9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Name(Dataset):\n",
        "  def __init__(self, csv_file, root_path, transform=None):\n",
        "  # def __init__(self, csv_file):\n",
        "    self.xy = pd.read_csv(csv_file)\n",
        "    self.root_dir = root_path\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __getitem__(self, id):\n",
        "    self.word = self.xy.iloc[id,:][0] #iloc will tell all element of row ( ie id) then last [no ie 0] is first element\n",
        "    self.country = self.xy.iloc[id,:][1]\n",
        "    # word1 = torch(word)\n",
        "    # conuntry1 = torch(country)\n",
        "    return self.word, self.country\n",
        "\n",
        "  def __len__(self):\n",
        "    self.len = self.xy.shape[0]\n",
        "    return self.len"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_3SaEO7eTZB",
        "colab_type": "text"
      },
      "source": [
        "tast2: Create dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln00GiUsq3Mg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1976bf7d-dc92-49ee-8a0d-a36471ec04d4"
      },
      "source": [
        "# train loader\n",
        "BS = 1\n",
        "# database = \n",
        "database = Name('/content/drive/My Drive/AI/basic/data/names_train/names_train.csv','/content/drive/My Drive/AI/basic/data/names_train' )\n",
        "train_loader = DataLoader(dataset=database, batch_size= BS, shuffle=True)\n",
        "# test_loader = \n",
        "print(len(database))\n",
        "print(database[2000])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13373\n",
            "('Samaha', 'Arabic')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Zsgm90nzpF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "22d014de-2f40-4c6a-9d23-b0d1ecadef9c"
      },
      "source": [
        "#test loader\n",
        "if __name__=='__main__':\n",
        "  database = Name('/content/drive/My Drive/AI/basic/data/names_train/names_test.csv','/content/drive/My Drive/AI/basic/data/names_train' )\n",
        "  # database = Name('names_test.csv')\n",
        "  print(len(database))\n",
        "  print(database[2000])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6699\n",
            "('Bakshanski', 'Russian')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VwFV7Z_eWCF",
        "colab_type": "text"
      },
      "source": [
        "task3: model: embedding, rnn, linear layer \n",
        "task4: optimizer\n",
        "task5: training\n",
        "taask6: test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqEmGV5GkBD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class net(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(net,self).__init__()\n",
        "    self.word_len = 18 # seq chenged from 15 to 18 for test\n",
        "    self.vocab_size = 6699 # no of words\n",
        "    self.embedding_dim =6 # how many diamention it wants\n",
        "    self.input_size = self.embedding_dim #6\n",
        "    self.hiddenO = self.input_size #6 dim\n",
        "    self.hidden_size = self.embedding_dim #6\n",
        "    self.batch = 1\n",
        "    self.num_layer =1\n",
        "    self.num_class = 18 #num of contries\n",
        "\n",
        "    #embedding\n",
        "    self.embed = nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embedding_dim)\n",
        "    #gru    \n",
        "    self.grucell = nn.GRU(input_size = self.input_size, hidden_size = self.hidden_size, num_layers =self.num_layer, batch_first = True)\n",
        "    #fc\n",
        "    self.fc = nn.Linear(in_features= self.embedding_dim, out_features= self.num_class)\n",
        "  \n",
        "  def forward(self, word, contry):\n",
        "    # word, contry = data\n",
        "    #converting work in to integer ASCII for input and outpuut ord\n",
        "    word_ascii, w_len = asc(word, self.word_len) #in: word * BS and out: ASCII * BS with padding\n",
        "    # challenge we need some padding. keep every word as 10 character long.\n",
        "    \n",
        "    word_embed = self.embed(word_ascii) #embedding e extra in matrix out : BS* word_len*E\n",
        "    #rnn in and out rnn_in BS*Seq*inu_D(e) and rnn_out BS*Seq*hiddenO\n",
        "    # input = B*Seq_len*input, hidden = num_lauyer* batch,hidden_size\n",
        "    input = word_embed # B*S*I\n",
        "    hidden = self.hidden_init()\n",
        "    out, h_n = self.grucell(input, hidden) #out B*S*hidden [1 10 6] , h_n = num_layerxBxHidden [1 1 6]\n",
        "\n",
        "    #FC linear layer in Seq to out no of classor contry(-1, nod of class or country)\n",
        "    out = self.fc(h_n) #in [1 1 6] out [1 1 18]\n",
        "    out = out.view(self.num_class, -1)\n",
        "    # out - out.t()\n",
        "    country, counry_len = asc(contry, self.word_len) # 18 contoury with each 15 word\n",
        "    country = country.t()#view(-1)\n",
        "    print(\"out shaepe\", out.shape, \"countey shape\", country.shape)\n",
        "    # country = country.squeeze_()\n",
        "    \n",
        "    # out = out.squeeze_()\n",
        "    return out, country\n",
        "\n",
        "    #output output of DC \n",
        "  def hidden_init(self):\n",
        "    hid = torch.zeros(self.num_layer, self.batch, self.hiddenO)\n",
        "    return \n",
        "\n",
        "  def asc(self, words, word_len):\n",
        "    word_len = word_len\n",
        "\n",
        "    for word in words:\n",
        "      # for cha in word:\n",
        "      sorks = [ord(cha) for cha in word]\n",
        "      sorks2 = sorks + [0]*(word_len-len(sorks)) \n",
        "      sorks3 = Variable(torch.LongTensor([sorks2]))\n",
        "    return sorks3, len(sorks2) \n",
        "\n",
        "  # sorks= []\n",
        "  # i=0\n",
        "  # def asc(self, words, word_len):\n",
        "  #   word_len = word_len\n",
        "\n",
        "  #   for word in words:\n",
        "  #     # for cha in word:\n",
        "  #     sorks = [ord(cha) for cha in word]\n",
        "  #     sorks2 = sorks + [0]*(word_len-len(sorks)) \n",
        "  #     sorks3 = Variable(torch.LongTensor([sorks2]))\n",
        "    # return sorks3, len(sorks2)\n",
        "model = net()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlsCGYjf5XtB",
        "colab_type": "text"
      },
      "source": [
        "Process contry differently as each contry will have unique no (one number not as matrix as word (N * no of class) will be comparing or predicting the perticular class. so its a one idea to keep perticular class as one number rather than keeping it as one class as array.\n",
        "\n",
        "TODO each contry as one unique no.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bkGf6xpwy60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = .001)\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdzgP6gTxXdp",
        "colab_type": "text"
      },
      "source": [
        "Trainig\n",
        "\n",
        "https://stackoverflow.com/questions/49206550/pytorch-error-multi-target-not-supported-in-crossentropyloss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8YXuz0AwyyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ff818c34-c475-43ad-a4b3-7d71574ebf12"
      },
      "source": [
        "for epoch in range(5):\n",
        "  for batch_id, (word, contry) in enumerate(train_loader):\n",
        "    out, country = model(word, contry)\n",
        "    # print(\"out shape\", out[0].shape, \"countey[1] shape\", country[1].shape)\n",
        "    print(\"out shape\", out.shape, \"countey[1] shape\", country.view(-1).shape)\n",
        "    optimizer.zero_grad()\n",
        "    loss = Criterion(out, country)\n",
        "    loss.backword()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 500  == 0:\n",
        "        print('Train Epoch: {} | Batch Status: {}/{} ({:.0f}%) | Loss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out shaepe torch.Size([18, 1]) countey shape torch.Size([18, 1])\n",
            "out shape torch.Size([18, 1]) countey[1] shape torch.Size([18])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-def528908fad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"out shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"countey[1] shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackword\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m--> 932\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2113\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gXI7sAowyhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhLo9HN7AiZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n= [\"name\"]\n",
        "# n[1]\n",
        "# ord(n[1])\n",
        "print(asc(n,10)[0].size())\n",
        "a, b = asc(n,10)\n",
        "embed=nn.Embedding(200,3)\n",
        "emb2 = embed(a)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOS2GPINm6EB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(emb2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoqHLwaEAqmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  sorks= []\n",
        "  i=0\n",
        "  def asc(words, word_len):\n",
        "    word_len = word_len\n",
        "\n",
        "    for word in words:\n",
        "      # for cha in word:\n",
        "      sorks = [ord(cha) for cha in word]\n",
        "      sorks2 = sorks + [0]*(word_len-len(sorks)) \n",
        "      sorks3 = Variable(torch.LongTensor([sorks2]))\n",
        "    return sorks3, len(sorks2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e02g7x7BWQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIyELK02B22g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n1 =asc(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzTcqLLZTcoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n2 = concat(n1, zeros[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqvdvxq4Th8f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "like_zero[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUWB-moTo_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}