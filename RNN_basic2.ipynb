{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_basic2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOyow3Cwz8RTHOrdd6sG5l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayk19/Assignment/blob/master/RNN_basic2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zWlwMgwJnGG",
        "colab_type": "text"
      },
      "source": [
        "https://towardsdatascience.com/pytorch-basics-how-to-train-your-neural-net-intro-to-rnn-cb6ebc594677"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7C1NhYaFLBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJYL1CxSFqgK",
        "colab_type": "text"
      },
      "source": [
        "input 1:20 , Batch Size = 4\n",
        "Sequence Length = 5\n",
        "Input Size = 1 (Since, only one dimension)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZb4c34pFYld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "35db73ad-2445-4256-f22f-85700cf86bb5"
      },
      "source": [
        "data = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])\n",
        "# data = torch.Tensor([range(1,21)])\n",
        "print(\"Data: \", data.shape, \"\\n\\n\", data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data:  torch.Size([20]) \n",
            "\n",
            " tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
            "        15., 16., 17., 18., 19., 20.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSRMZCzqGzjN",
        "colab_type": "text"
      },
      "source": [
        "Vanilla RNN \n",
        "\n",
        "1. define inputs parameter: input and h0\n",
        "\n",
        "Input\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "\n",
        "  seq_length = 5 # length if longest sequence\n",
        "\n",
        "  batch= 4 # no of batches\n",
        "\n",
        "  input_size = 1 # no of imput dimention\n",
        "\n",
        "   num_ layer =1 no of stacked enn layer\n",
        "\n",
        "h0\n",
        "\n",
        "2. output parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTmOOkmxI6Ik",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OdcbO3iI9C5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H2pYrWGFZDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imputs = input & ho\n",
        "#input\n",
        "seq_length = 5 # length if longest sequence \n",
        "batch= 4 # no of batches\n",
        "input_size = 1 # no of imput dimention\n",
        "# using batch_first [b s i]\n",
        "#h0\n",
        "num_layer =1 # nos of stacked rnn layers\n",
        "num_direction =1 # 2 for bi\n",
        "#batch = 4 #same as input $$$$\n",
        "hidden_size_h0 = input_size #Note"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtVD8Hk1FZSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Outputs = output, hn\n",
        "# Output\n",
        "seq_lengthO = 5 # note length if longest sequence \n",
        "batchO= 4 # no of batches\n",
        "# num_directionO = 1 ? # no of input dimention\n",
        "hidden_sizeO = 2 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjBHGC5KPa5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the RNN. ? what is function\n",
        "rnn = nn.RNN(input_size=input_size, hidden_size=hidden_sizeO, num_layers= num_layer, batch_first=True)\n",
        "# input size : (batch, seq_len, input_size)\n",
        "inputs = data.view(batch, seq_length, input_size)\n",
        "h_o = torch.randn(1,4,2) # ho:  (num_layers * num_directions, batch, hidden_size)\n",
        "# out shape = (batch, seq_len, num_directions * hidden_size)\n",
        "# h_n shape  = (num_layers * num_directions, batch, hidden_size)\n",
        "out, h_n = rnn(inputs, h_o) # can ignore h_0 as well"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_z89GF_Q0sL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "556274ec-ed53-4964-d2b4-6a1d7729b53d"
      },
      "source": [
        "print('Input: ', inputs.shape, '\\n', inputs)# input shape = [4, 5, 1]\n",
        "print('\\nOutput: ', out.shape, '\\n', out)# out shape = [4, 5, 2]\n",
        "print('\\nHidden: ', h_n.shape, '\\n', h_n)# h_n shape = [1, 4, 2]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([4, 5, 1]) \n",
            " tensor([[[ 1.],\n",
            "         [ 2.],\n",
            "         [ 3.],\n",
            "         [ 4.],\n",
            "         [ 5.]],\n",
            "\n",
            "        [[ 6.],\n",
            "         [ 7.],\n",
            "         [ 8.],\n",
            "         [ 9.],\n",
            "         [10.]],\n",
            "\n",
            "        [[11.],\n",
            "         [12.],\n",
            "         [13.],\n",
            "         [14.],\n",
            "         [15.]],\n",
            "\n",
            "        [[16.],\n",
            "         [17.],\n",
            "         [18.],\n",
            "         [19.],\n",
            "         [20.]]])\n",
            "\n",
            "Output:  torch.Size([4, 5, 2]) \n",
            " tensor([[[ 0.8822,  0.9647],\n",
            "         [-0.3763,  0.8608],\n",
            "         [ 0.2885,  0.8774],\n",
            "         [ 0.2583,  0.9588],\n",
            "         [ 0.4025,  0.9779]],\n",
            "\n",
            "        [[ 0.6028,  0.9961],\n",
            "         [ 0.5993,  0.9958],\n",
            "         [ 0.7144,  0.9980],\n",
            "         [ 0.7850,  0.9991],\n",
            "         [ 0.8444,  0.9996]],\n",
            "\n",
            "        [[ 0.9899,  0.9999],\n",
            "         [ 0.9173,  0.9999],\n",
            "         [ 0.9467,  1.0000],\n",
            "         [ 0.9634,  1.0000],\n",
            "         [ 0.9752,  1.0000]],\n",
            "\n",
            "        [[ 0.9975,  1.0000],\n",
            "         [ 0.9886,  1.0000],\n",
            "         [ 0.9924,  1.0000],\n",
            "         [ 0.9949,  1.0000],\n",
            "         [ 0.9966,  1.0000]]], grad_fn=<TransposeBackward1>)\n",
            "\n",
            "Hidden:  torch.Size([1, 4, 2]) \n",
            " tensor([[[0.4025, 0.9779],\n",
            "         [0.8444, 0.9996],\n",
            "         [0.9752, 1.0000],\n",
            "         [0.9966, 1.0000]]], grad_fn=<StackBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpMiM5Z5tfJZ",
        "colab_type": "text"
      },
      "source": [
        "Stacket RNN 3 layers stacked\n",
        "num_layer =3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF9wC9Vzta_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_layer= 3\n",
        "rnn = nn.RNN(input_size, hidden_sizeO, num_layer, batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0vOKIrqwTWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a33d9a90-12c4-4723-f4f5-cfce0872bb2a"
      },
      "source": [
        "input = data.view(batch,seq_length,input_size)\n",
        "h_o = torch.zeros(num_layer*num_direction, batch, hidden_sizeO)\n",
        "print('Input: ', inputs.shape, 'h_o', h_o.shape, )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([4, 5, 1]) h_o torch.Size([3, 4, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axtBR4jfyAL4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "79ebcdd5-a316-49ce-e6e9-480fdb2957c6"
      },
      "source": [
        "# out, h_n = rnn(input, h_o)\n",
        "out, h_n = rnn(input)\n",
        "print('out: ', out.shape, 'h_n', h_n.shape )"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out:  torch.Size([4, 5, 2]) h_n torch.Size([3, 4, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHOi1HEzOAe",
        "colab_type": "text"
      },
      "source": [
        "**Bitidection RNN**: paramerter (bidirection = true), h_0 or h_n: num_direection =2\n",
        "\n",
        "(if not made num_direction at h_0 then it will come automatically at h_n)  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhnLvWEpxnV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b92da39f-b1f3-4dea-ba2d-e3fc13ca8d2b"
      },
      "source": [
        "num_direction =2\n",
        "num_layer =1\n",
        "rnn = nn.RNN(input_size, hidden_sizeO, num_layer, bidirectional= True, batch_first=True)\n",
        "input = data.view(batch, seq_length, input_size) #input size : (batch, seq_len, input_size)\n",
        "h_o = torch.zeros(num_layer*num_direction, batch, hidden_sizeO)#ho:  (num_layers * num_directions, batch, hidden_size)\n",
        "print('Input: ', inputs.shape, 'h_o', h_o.shape, )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input:  torch.Size([4, 5, 1]) h_o torch.Size([2, 4, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILKZNjTu09oz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "446f0af5-c30e-499f-cbb0-3d3f9c267a74"
      },
      "source": [
        "# out, h_n = rnn(input, h_o)\n",
        "out, h_n = rnn(input)\n",
        "print('out: ', out.shape, 'h_n', h_n.shape )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "out:  torch.Size([4, 5, 4]) h_n torch.Size([2, 4, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTEUZfjA1NLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Input: ', inputs.shape, '\\n', inputs)# input shape = [4, 5, 1]\n",
        "print('\\nOutput: ', out.shape, '\\n', out)# out shape = [4, 5, 2]\n",
        "print('\\nHidden: ', h_n.shape, '\\n', h_n)# h_n shape = [1, 4, 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k49C4XAy4Cy-",
        "colab_type": "text"
      },
      "source": [
        "**BIRNN seperated out (not h_n**\n",
        "\n",
        "Let’s **reshape the BiRNN output** to separate out** forward and backward values **using    :\n",
        "\n",
        " out.view(batch, seq_len, num_directions, hidden_size)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzmQ_G6c4Ceq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2357928c-4f15-41f9-ce10-883dcc317ebb"
      },
      "source": [
        "out_reshaped = out.view(batch, seq_length, num_direction, hidden_sizeO)\n",
        "print(\"Shape of the output after directions are separated: \", out_reshaped.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the output after directions are separated:  torch.Size([4, 5, 2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylFo6N0u4COI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_forward = out_reshaped[:, :, 0, :]\n",
        "out_backward = out_reshaped[:, :, 1, :]\n",
        "print(\"Forward output: \", out_forward.shape, \"\\n\", out_forward)\n",
        "print(\"\\n\\nBackward output: \", out_backward.shape, \"\\n\", out_backward)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK47tXhg09Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "**BIRNN seperated h_n**\n",
        "\n",
        "Let’s **reshape the BiRNN h_n** to separate out** forward and backward values **using    :\n",
        "\n",
        "h_n.view(num_layer, num_direction, batch, hidden_sizeO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUo8OjtI1sDW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "904e416f-c015-441f-ef0a-00a53ea0c37d"
      },
      "source": [
        "h_n_reshaped = h_n.view(num_layer, num_direction, batch, hidden_sizeO)\n",
        "print(\"Shape of the output after directions are separated: \", h_n_reshaped.shape, '\\n', h_n_reshaped)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the output after directions are separated:  torch.Size([1, 2, 4, 2]) \n",
            " tensor([[[[ 0.6057,  0.2082],\n",
            "          [ 0.4775,  0.1011],\n",
            "          [ 0.3182, -0.0119],\n",
            "          [ 0.1338, -0.1272]],\n",
            "\n",
            "         [[ 0.7576, -0.0838],\n",
            "          [ 0.9072, -0.9966],\n",
            "          [ 0.9680, -1.0000],\n",
            "          [ 0.9893, -1.0000]]]], grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwS6NfYC12p8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "f8b2d265-c7c9-4c7d-cf7e-be984cf6cadf"
      },
      "source": [
        "h_n_forward = h_n_reshaped[:, 0, :, :]\n",
        "h_n_backward = h_n_reshaped[:, 1, :, :]\n",
        "print(\"Forward output: \", h_n_forward.shape, \"\\n\", h_n_forward)\n",
        "print(\"\\n\\nBackward output: \", h_n_backward.shape, \"\\n\", h_n_backward)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Forward output:  torch.Size([1, 4, 2]) \n",
            " tensor([[[ 0.6057,  0.2082],\n",
            "         [ 0.4775,  0.1011],\n",
            "         [ 0.3182, -0.0119],\n",
            "         [ 0.1338, -0.1272]]], grad_fn=<SliceBackward>)\n",
            "\n",
            "\n",
            "Backward output:  torch.Size([1, 4, 2]) \n",
            " tensor([[[ 0.7576, -0.0838],\n",
            "         [ 0.9072, -0.9966],\n",
            "         [ 0.9680, -1.0000],\n",
            "         [ 0.9893, -1.0000]]], grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFt_PNGD2Hgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}