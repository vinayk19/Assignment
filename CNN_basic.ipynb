{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN basic.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSMVT0a2C/00NogozEyXE7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vinayk19/Assignment/blob/master/CNN_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEKQA1W7aWZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pvEPDXpasgg",
        "colab_type": "text"
      },
      "source": [
        "# **Conv2d 1d** Example 1d\\\n",
        "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
        "\n",
        "So the in_channels in the beginning is 3 for images with 3 channels (colored images). For images black and white it should be 1. Some satellite images should have 4.\n",
        "\n",
        "The out_channels is what convolution will produce so these are the **number of filters.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQu1NUomaoG-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "3a3a2efa-3c46-4e52-f22e-c74566b3a586"
      },
      "source": [
        " c = torch.nn.Conv2d(1,3, stride = 1, kernel_size = (4,5))\n",
        " print(c.weight.shape)\n",
        " print(c.weight)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 1, 4, 5])\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.2182, -0.1086, -0.1316, -0.0397,  0.1063],\n",
            "          [-0.1451, -0.1484,  0.1554, -0.0186,  0.0261],\n",
            "          [-0.0700,  0.1159, -0.1921,  0.2216,  0.0835],\n",
            "          [-0.1352, -0.0753, -0.1653, -0.1486, -0.0995]]],\n",
            "\n",
            "\n",
            "        [[[-0.1097, -0.1166,  0.1925, -0.1203,  0.0226],\n",
            "          [ 0.0565,  0.0950,  0.1264,  0.0300,  0.0145],\n",
            "          [-0.0995,  0.1317, -0.0858, -0.1637, -0.1270],\n",
            "          [-0.0653, -0.1054,  0.0852, -0.0463,  0.1963]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1061,  0.0150,  0.1275,  0.1682, -0.2122],\n",
            "          [-0.0175,  0.0910, -0.2110,  0.1512,  0.0553],\n",
            "          [-0.0935,  0.1005, -0.0046, -0.1503,  0.0584],\n",
            "          [-0.1342, -0.2112, -0.1114, -0.1706, -0.1445]]]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M04UlLt6bZiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "195ff46b-b79c-49a2-c041-dd8218029c1e"
      },
      "source": [
        " c = torch.nn.Conv2d(1,5, stride = 1, kernel_size = (4,5))\n",
        " print(c.weight.shape)\n",
        " print(c.weight)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 1, 4, 5])\n",
            "Parameter containing:\n",
            "tensor([[[[ 1.9351e-01, -1.8174e-01, -4.7789e-02, -1.4406e-01, -1.7552e-02],\n",
            "          [ 1.7000e-01, -1.3898e-01,  4.8733e-03,  2.0059e-01, -7.2878e-02],\n",
            "          [ 1.2508e-02,  1.9801e-01, -3.6867e-02,  1.2918e-01, -1.5179e-01],\n",
            "          [-1.3442e-01, -1.2397e-01,  8.5477e-02,  2.1917e-01, -1.1915e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.0836e-01, -1.0360e-01,  1.0292e-01, -2.2175e-01,  9.9093e-02],\n",
            "          [ 1.1426e-01, -1.8283e-01,  5.9316e-02, -5.0230e-02,  4.0918e-02],\n",
            "          [ 1.7779e-01, -7.1195e-02,  2.0888e-01, -1.3882e-02,  1.4721e-01],\n",
            "          [ 9.9359e-02, -2.1198e-01, -1.4503e-02,  2.8081e-02,  1.7089e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4866e-01, -1.3066e-01,  8.0951e-03, -1.7019e-01, -1.2110e-02],\n",
            "          [ 2.1631e-01, -3.6557e-02, -9.3217e-02,  1.9946e-01, -3.9478e-02],\n",
            "          [ 1.2499e-01, -1.4847e-01, -4.2959e-02, -1.3678e-01, -1.8746e-01],\n",
            "          [-1.9732e-01, -3.9062e-03,  8.9821e-02, -8.7414e-02, -1.1592e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4269e-04, -1.0678e-01, -1.3897e-01,  1.1618e-02, -2.0714e-01],\n",
            "          [ 1.6879e-01,  1.4176e-01,  1.5758e-01,  1.8992e-01,  5.1422e-02],\n",
            "          [-1.3942e-01, -2.1910e-01, -1.4383e-01, -1.4623e-01,  2.0076e-01],\n",
            "          [ 9.3225e-02, -5.4112e-03,  1.7035e-01, -2.1956e-01,  1.3977e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0341e-01,  1.6656e-01,  1.2191e-01, -1.6540e-01,  1.4139e-01],\n",
            "          [-1.5157e-01,  7.8211e-02,  1.4472e-01,  4.5713e-02,  1.1049e-01],\n",
            "          [ 2.1730e-02, -1.5758e-01,  1.9698e-02, -5.7554e-02, -4.2580e-02],\n",
            "          [-8.3243e-02,  2.3048e-02,  7.7449e-02, -1.9378e-01, -5.9155e-02]]]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tyiw9dMcGKs",
        "colab_type": "text"
      },
      "source": [
        "2 in channel and 3 filter\n",
        "**Note : no of channel at input and output remains same ie 2 althogh changed filter**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbvYRoRcb6p0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "52947a90-19af-49b2-a2fb-395dbeb2aeb6"
      },
      "source": [
        "c = torch.nn.Conv2d(2,3, stride = 1, kernel_size = (4,5)) #( 3 output fileter)\n",
        "print(c.type)\n",
        "print(c.weight.shape)\n",
        "print(c.weight)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.type of Conv2d(2, 3, kernel_size=(4, 5), stride=(1, 1))>\n",
            "torch.Size([3, 2, 4, 5])\n",
            "Parameter containing:\n",
            "tensor([[[[-0.1008,  0.0610, -0.0912, -0.1417,  0.1253],\n",
            "          [ 0.0815, -0.0631, -0.1209,  0.0789, -0.0761],\n",
            "          [ 0.1364, -0.0093,  0.1035,  0.0808,  0.1108],\n",
            "          [ 0.1236, -0.0196, -0.0164, -0.0367, -0.1192]],\n",
            "\n",
            "         [[-0.0820,  0.0768, -0.0780,  0.0970,  0.0208],\n",
            "          [-0.1225,  0.1247,  0.0534,  0.1563,  0.0732],\n",
            "          [-0.0702, -0.1250, -0.1464, -0.0714,  0.1119],\n",
            "          [ 0.0260, -0.0633, -0.0542,  0.0363, -0.0927]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0434,  0.1048,  0.0040, -0.1115,  0.1095],\n",
            "          [ 0.1367,  0.0211,  0.0593,  0.1111,  0.0292],\n",
            "          [-0.0403, -0.1147, -0.1275, -0.1088, -0.0635],\n",
            "          [ 0.0683,  0.1155, -0.1024, -0.0580, -0.0522]],\n",
            "\n",
            "         [[ 0.0749, -0.0551, -0.0264, -0.0570,  0.0011],\n",
            "          [-0.0637,  0.0669, -0.1523,  0.1468, -0.0625],\n",
            "          [-0.0571,  0.0146,  0.0365,  0.1455,  0.0589],\n",
            "          [-0.0923,  0.0865, -0.1199,  0.0090,  0.0315]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0985, -0.0701,  0.0442, -0.1567, -0.1554],\n",
            "          [-0.0396, -0.0468,  0.0169,  0.1336,  0.0908],\n",
            "          [-0.0340,  0.0166,  0.1496,  0.1320, -0.0536],\n",
            "          [-0.0427, -0.0925,  0.1252, -0.1048, -0.1074]],\n",
            "\n",
            "         [[ 0.0028, -0.1233, -0.0530,  0.0787,  0.0634],\n",
            "          [-0.0769, -0.1576,  0.0654, -0.0434, -0.1031],\n",
            "          [ 0.0269,  0.0473,  0.1246, -0.1278,  0.0080],\n",
            "          [-0.0958, -0.0249, -0.1522,  0.1312,  0.0599]]]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLpYPdSFiK-I",
        "colab_type": "text"
      },
      "source": [
        "applying con2d in **Input data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlLgUtK4fPEt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "9804c047-630a-4f58-ed3e-0272fd251493"
      },
      "source": [
        "bs=4\n",
        "x = torch.randn(bs, 3, 28, 28)\n",
        "c = torch.nn.Conv2d(3,2,kernel_size=5,stride=1,padding=2) # in channel =3 seen same 3 at x(input) which is channel. ip has image of 28*28 with 3 cahnnel \n",
        "print(\"conv2d type \", c.type)\n",
        "print(\"conv2d shape \",c.weight.shape)\n",
        "print(\"conv2d weight \",c.weight)\n",
        "out = c(x)\n",
        "print(\"out type \", out.type)\n",
        "# print(out.weight.shape)\n",
        "# print(out.weight)\n",
        "print(\"out shape \",out.shape)\n",
        "print(out.nelement()) #125440 number of activations"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d type  <bound method Module.type of Conv2d(3, 2, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))>\n",
            "conv2d shape  torch.Size([2, 3, 5, 5])\n",
            "conv2d weight  Parameter containing:\n",
            "tensor([[[[ 0.0116,  0.0465, -0.0911, -0.0530, -0.1102],\n",
            "          [ 0.0666, -0.0053,  0.0467,  0.0217, -0.0732],\n",
            "          [ 0.0378,  0.0937,  0.0272,  0.0680, -0.0773],\n",
            "          [-0.0503, -0.0512,  0.1082,  0.0934, -0.0902],\n",
            "          [ 0.0662,  0.1128,  0.0461, -0.0746, -0.0960]],\n",
            "\n",
            "         [[-0.0118,  0.1104, -0.0027,  0.0875, -0.0088],\n",
            "          [ 0.0590, -0.1059,  0.0965,  0.0942, -0.0044],\n",
            "          [ 0.0565,  0.0995,  0.0743,  0.0984,  0.0183],\n",
            "          [ 0.0594, -0.0735, -0.0311,  0.0824, -0.1020],\n",
            "          [-0.0374,  0.0173,  0.0786,  0.0959,  0.0122]],\n",
            "\n",
            "         [[-0.0433,  0.0125,  0.1094, -0.1057, -0.0302],\n",
            "          [ 0.0812, -0.1005,  0.0622,  0.0281,  0.0655],\n",
            "          [ 0.0076, -0.0006,  0.0321,  0.0445, -0.0756],\n",
            "          [ 0.0491,  0.0275,  0.0194,  0.0539,  0.0625],\n",
            "          [-0.0039,  0.1067,  0.0905, -0.0623, -0.0788]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0975, -0.0713,  0.0603,  0.0034, -0.1026],\n",
            "          [-0.0439,  0.0899,  0.0703,  0.0395,  0.0097],\n",
            "          [-0.0664,  0.0648, -0.1137,  0.0511,  0.0364],\n",
            "          [-0.1143,  0.0867,  0.0591, -0.0158,  0.0242],\n",
            "          [-0.0281, -0.1089,  0.0198,  0.0111, -0.0183]],\n",
            "\n",
            "         [[ 0.0892, -0.0665,  0.1050,  0.0213, -0.1011],\n",
            "          [ 0.0795, -0.0089,  0.0870, -0.0770, -0.0027],\n",
            "          [-0.0120,  0.1041,  0.0440,  0.0453, -0.0748],\n",
            "          [ 0.0223,  0.0633, -0.0422, -0.0111,  0.0590],\n",
            "          [ 0.0951,  0.0395,  0.0916, -0.0903, -0.0381]],\n",
            "\n",
            "         [[ 0.0939, -0.0945,  0.0071, -0.0761, -0.1108],\n",
            "          [-0.0095, -0.0202, -0.0248, -0.0981,  0.0021],\n",
            "          [ 0.0835,  0.0167, -0.0739,  0.0516,  0.0332],\n",
            "          [ 0.0606, -0.0980, -0.0491,  0.0849, -0.0899],\n",
            "          [ 0.1060,  0.0282,  0.0300,  0.0116, -0.0749]]]], requires_grad=True)\n",
            "out type  <built-in method type of Tensor object at 0x7f0de37427e0>\n",
            "out shape  torch.Size([4, 2, 28, 28])\n",
            "6272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmfWOrIZjudZ",
        "colab_type": "text"
      },
      "source": [
        "**Max POOL**\n",
        "MaxPool2d , MaxPool1d etc\n",
        "\n",
        "torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfyAIVnKf9jQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a6edc57-30ce-4877-e6ab-5c618f821734"
      },
      "source": [
        "m = torch.nn.MaxPool2d(kernel_size=2)\n",
        "print(\"conv2d type \", m.type)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv2d type  <bound method Module.type of MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64CDk3nMk3u3",
        "colab_type": "text"
      },
      "source": [
        "Applying MaxPool2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEW0VCWuk2_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_MP = m(out)\n",
        "print(\"input to MP \", out.shape)\n",
        "print(\"out_MP type \", out_MP.type)\n",
        "print(\"output shape of of maxpool is \", out_MP.shape)\n",
        "print(out_MP.nelement()) #  number of activations\n",
        "out_MP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rNJbCoqk2xn",
        "colab_type": "text"
      },
      "source": [
        "# Applying Activation Function ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2I6oRPvf_Wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z= torch.nn.ReLU()  # need to check its type shape and values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ruht3Jzr8jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_act = z(out_MP) # applied activation but need to check its type shape and values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CCGVWe4sL6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_flattening = out_act.view(x, -1) #flattening as input x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhUMT5E23DAy",
        "colab_type": "text"
      },
      "source": [
        "need to flatten values\n",
        "apply funny linear layer (nn. linear)\n",
        "apply softmax above that"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-V8ywAW3Aox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a41cP7lJ2wFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}